{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwHi7ns7t-Fh"
      },
      "source": [
        "### １０章　ディープラーニングモデル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdytJsj7uENZ"
      },
      "source": [
        "### 必要ライブラリの導入"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVoHxKlxtvun"
      },
      "outputs": [],
      "source": [
        "# 日本語化ライブラリ導入\n",
        "!pip install japanize-matplotlib -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcYb9AsPuBZN"
      },
      "outputs": [],
      "source": [
        "# 共通事前処理\n",
        "\n",
        "# 必要ライブラリのimport\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# matplotlib日本語化対応\n",
        "import japanize_matplotlib\n",
        "\n",
        "# Numpyで浮動小数点表示を固定する\n",
        "np.set_printoptions(formatter={'float': '{:0.3f}'.format})\n",
        "\n",
        "# データフレーム表示用関数\n",
        "from IPython.display import display\n",
        "\n",
        "# pandasでの浮動小数点の表示精度\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "\n",
        "# 余分なワーニングを非表示にする\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10-7 プログラム実装(データ準備・加工)"
      ],
      "metadata": {
        "id": "1ZgvsLBD89J-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MgwqQ45uTIX"
      },
      "source": [
        "### データ読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7GzmDW-uYQi"
      },
      "source": [
        "#### 読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q175_b_SuQuo"
      },
      "outputs": [],
      "source": [
        "# データ読み込み\n",
        "\n",
        "# データ読み込み用ライブラリのインポート\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "# 訓練データ\n",
        "train_dataset = MNIST(root=\"./data\", train=True, download=True)\n",
        "\n",
        "# テストデータ\n",
        "test_dataset = MNIST(root=\"./data\", train=False, download=True)\n",
        "\n",
        "# NumPy 配列に変換\n",
        "x_train_np = train_dataset.data.numpy().reshape(-1, 28*28)\n",
        "y_train_np = train_dataset.targets.numpy()\n",
        "\n",
        "x_test_np = test_dataset.data.numpy().reshape(-1, 28*28)\n",
        "y_test_np = test_dataset.targets.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 内容表示"
      ],
      "metadata": {
        "id": "xcaWvL4wGVOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 内容表示\n",
        "\n",
        "# 4つの変数のshape確認\n",
        "print(x_train_np.shape, y_train_np.shape, x_test_np.shape, y_test_np.shape)\n",
        "\n",
        "# y_test_npの先頭10要素\n",
        "print(y_test_np[:10])\n",
        "\n",
        "# x_test_npの最初の要素\n",
        "print(x_test_np[0])"
      ],
      "metadata": {
        "id": "DcxjJScJGbzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### イメージ表示"
      ],
      "metadata": {
        "id": "_bx3TsoYGcci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# イメージ表示\n",
        "N1 = 10 # 横個数\n",
        "N2 = 5  # 縦個数\n",
        "N = N1 * N2 # 10*5 = 50個\n",
        "\n",
        "# テストデータからランダムに50個のイメージを抽出\n",
        "# 再現性があるようにseed値をセットしておく\n",
        "np.random.seed(12)\n",
        "indexes = np.random.choice(y_test_np.shape[0], N, replace=False)\n",
        "x_selected = x_test_np[indexes]\n",
        "y_selected = y_test_np[indexes]\n",
        "\n",
        "# 50個の描画領域を設定\n",
        "plt.figure(figsize=(N1, N2), tight_layout=True)\n",
        "for i in range(N):\n",
        "    # 個別イメージの描画位置指定\n",
        "    ax = plt.subplot(N2, N1, i + 1)\n",
        "\n",
        "    # イメージ表示\n",
        "    ax.imshow(x_selected[i].reshape(28, 28), cmap='gray_r')\n",
        "\n",
        "    # 正解ラベルを画像のタイトルとして表示\n",
        "    ax.set_title(f'{int(y_selected[i]):d}', fontsize=12)\n",
        "\n",
        "    # 軸ラベル非表示\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UgDtFYuiGfgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H82FRtbExNax"
      },
      "source": [
        "### データ加工"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv5T9xOBxTFv"
      },
      "source": [
        "#### xの正規化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo3kTdhcu2Ov"
      },
      "outputs": [],
      "source": [
        "# xの正規化\n",
        "x_train_norm_np = x_train_np / 255.0\n",
        "x_test_norm_np = x_test_np / 255.0\n",
        "\n",
        "# 先頭にダミー変数を追加\n",
        "x_train_dum_np = np.insert(x_train_norm_np, 0, 1, axis=1)\n",
        "x_test_dum_np = np.insert(x_test_norm_np, 0, 1, axis=1)\n",
        "\n",
        "# shapeを表示\n",
        "print(x_train_dum_np.shape, x_test_dum_np.shape)\n",
        "\n",
        "# 結果の先頭要素を表示\n",
        "print('x_train_dum_np[0]\\n', x_train_dum_np[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyrgLqgkx0g4"
      },
      "source": [
        "#### 正解値のOne Hotベクトル化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ifBAXFlxiyw"
      },
      "outputs": [],
      "source": [
        "# 正解値のOne Hotベクトル化\n",
        "\n",
        "# OneHotEncoderのインポート\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# one hot encoderインスタンスの生成\n",
        "ohe = OneHotEncoder(sparse_output=False,categories='auto')\n",
        "\n",
        "# y_train_npのOne Hotベクトル化\n",
        "y_train_ohe_np = ohe.fit_transform(y_train_np.reshape(-1, 1))\n",
        "\n",
        "# y_test_npのOne Hotベクトル化\n",
        "y_test_ohe_np = ohe.transform(y_test_np.reshape(-1, 1))\n",
        "\n",
        "# 各変数のshape確認\n",
        "print('y_train One Hot Vector化前', y_train_np.shape)\n",
        "print('y_train One Hot Vector化後', y_train_ohe_np.shape)\n",
        "print('y_test One Hot Vector化前', y_test_np.shape)\n",
        "print('y_test One Hot Vector化後', y_test_ohe_np.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX4jFbE8105z"
      },
      "source": [
        "## 10-8 プログラム実装(GPU利用)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1Y12OrHWQRJ"
      },
      "source": [
        "#### Tensor型に変換"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3ywUose5jgq"
      },
      "outputs": [],
      "source": [
        "# Tensor型に変換\n",
        "\n",
        "# PyTorchのインポート\n",
        "import torch\n",
        "\n",
        "# NumPy変数をTensor変数に変換\n",
        "x_train = torch.Tensor(x_train_dum_np).float()\n",
        "y_train = torch.Tensor(y_train_np).float()\n",
        "y_train_ohe = torch.Tensor(y_train_ohe_np).float()\n",
        "x_test = torch.Tensor(x_test_dum_np).float()\n",
        "y_test = torch.Tensor(y_test_np).float()\n",
        "y_test_ohe = torch.Tensor(y_test_ohe_np).float()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeRlGi1F5KAv"
      },
      "source": [
        "#### GPU 存在チェック"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU存在チェック\n",
        "\n",
        "# GPUが利用可能かどうかのチェック\n",
        "device = torch.device(\"cuda:0\" \\\n",
        "if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 利用可能な場合は\"cuda:0\"が出力される\n",
        "print(device)"
      ],
      "metadata": {
        "id": "KPc3irlvik5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensor型データをGPUに転送"
      ],
      "metadata": {
        "id": "ofEq05Y7DAUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor型データをGPUに転送\n",
        "\n",
        "# 訓練データをGPUに転送\n",
        "x_train_gpu = x_train.to(device)\n",
        "y_train_gpu = y_train.to(device)\n",
        "y_train_ohe_gpu = y_train_ohe.to(device)\n",
        "\n",
        "# テストデータをGPUに転送\n",
        "x_test_gpu = x_test.to(device)\n",
        "y_test_gpu = y_test.to(device)\n",
        "y_test_ohe_gpu = y_test_ohe.to(device)"
      ],
      "metadata": {
        "id": "mTDdP3OLtWqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10-9 プログラム実装(ミニバッチ学習法・関数定義)"
      ],
      "metadata": {
        "id": "B50f3ceKITO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ミニバッチ学習法"
      ],
      "metadata": {
        "id": "RoGFJ4x-InjI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### データローダーの定義"
      ],
      "metadata": {
        "id": "7vCBHfBcI3pL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データローダーの定義\n",
        "\n",
        "# 必要ライブラリのインポート\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# 0から19までの1次元配列をTensorDatasetとして定義\n",
        "dataset = TensorDataset(torch.arange(20))\n",
        "\n",
        "# datasetを5個ずつのグループで取り出すようにデータローダーを定義\n",
        "loader = DataLoader(dataset, batch_size=5, shuffle=True)"
      ],
      "metadata": {
        "id": "O3u9EySyIq2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### データローダーの利用イメージ"
      ],
      "metadata": {
        "id": "Oeyh5G_vI7Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データローダーの利用イメージ\n",
        "# 繰り返し回数(nb_epoch)=2で上記ローダを利用する\n",
        "\n",
        "# 繰り返し回数の定義\n",
        "nb_epoch = 2\n",
        "for epoch in range(nb_epoch):\n",
        "    print(f'epoch = {epoch}')\n",
        "\n",
        "    # データローダーから5個ずつのグループにしたデータをbatchとして取得\n",
        "    for batch in loader:\n",
        "        print(batch[0].numpy())"
      ],
      "metadata": {
        "id": "FCHgTgh3I_TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L24BzQAX0BnP"
      },
      "source": [
        "### 関数定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSA_qNl0w9Ls"
      },
      "source": [
        "#### 汎用関数\n",
        "シグモイド関数とsoftmax関数はPyTorch標準関数を利用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zy2N2sZzj6v"
      },
      "outputs": [],
      "source": [
        "# 汎用関数\n",
        "\n",
        "# PyTorch標準関数用ライブラリのインポート\n",
        "import torch.nn as nn\n",
        "\n",
        "# シグモイド関数の定義\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "# softmax関数の定義\n",
        "softmax = nn.Softmax(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2ZmkYw4x9La"
      },
      "source": [
        "#### 交差エントロピー関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YECejl_u3-wn"
      },
      "outputs": [],
      "source": [
        "# 交差エントロピー関数\n",
        "# PyTorchの交差エントロピー関数はわかりにくいのでスクラッチで実装\n",
        "\n",
        "def cross_entropy(yt_ohe, yp_ohe):\n",
        "    return -torch.mean(torch.sum(yt_ohe * torch.log(yp_ohe), dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8XB_pt6zPiN"
      },
      "source": [
        "#### 評価関数\n",
        "損失と精度を計算"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwvV5Le2v-jR"
      },
      "outputs": [],
      "source": [
        "# 評価関数\n",
        "# 重み行列V, Wから学習中の損失と精度を計算\n",
        "\n",
        "# accuracy_scoreは精度評価のための関数\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate(x_test, y_test, y_test_ohe, x_dum, V, W):\n",
        "\n",
        "    # テストデータに対して隠れ層の値を計算\n",
        "    b_test = sigmoid(x_test @ V)\n",
        "\n",
        "    # ダミー変数追加\n",
        "    b1_test = torch.cat((x_dum, b_test), dim=1)\n",
        "\n",
        "    # 予測値の計算(確率値)\n",
        "    yp_test_ohe = softmax(b1_test @ W)\n",
        "\n",
        "    # 予測クラス計算(0から9の整数)\n",
        "    yp_test = torch.argmax(yp_test_ohe, dim=1)\n",
        "\n",
        "    # 損失計算(item関数でスカラー化)\n",
        "    loss = cross_entropy(y_test_ohe, yp_test_ohe).item()\n",
        "\n",
        "    # 精度計算(item関数でスカラー化)\n",
        "    score = (y_test == yp_test).float().mean().item()\n",
        "\n",
        "    return score, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47BKp4NN1iL6"
      },
      "source": [
        "## 10-10 プログラム実装(学習その1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習"
      ],
      "metadata": {
        "id": "hwjU_j8rLEcw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDyHfvVm1k1p"
      },
      "source": [
        "#### 学習関数1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMGuYqsA1VwB"
      },
      "outputs": [],
      "source": [
        "# 学習関数1\n",
        "\n",
        "def train_mlp(\n",
        "    hidden_units=100, epochs=500, batch_size=500, alpha_np=0.01,\n",
        "    his_unit=10):\n",
        "    \"\"\"\n",
        "    2層（入力→Sigmoid→出力Softmax）の単純なMLPを、\n",
        "    勾配降下法で学習する関数。\n",
        "    返り値: (V, W, history[epoch, loss, acc])\n",
        "    \"\"\"\n",
        "    # M: 訓練用系列データ総数\n",
        "    # D: 入力データ次元数\n",
        "    M, D  = x_train.shape\n",
        "    # N: 分類クラス数\n",
        "    N = y_train_ohe.shape[1]\n",
        "    # 隠れ層のノード数\n",
        "    H = hidden_units\n",
        "    H1 = H + 1\n",
        "    # 重み行列の初期設定\n",
        "    np.random.seed(123)\n",
        "    V_np = np.ones((D, H))\n",
        "    W_np = np.ones((H1, N))\n",
        "    # GPU転送\n",
        "    alpha = torch.tensor(alpha_np).float().to(device)\n",
        "    V = torch.tensor(V_np).float().to(device)\n",
        "    W = torch.tensor(W_np).float().to(device)\n",
        "\n",
        "    # 学習時のダミー変数\n",
        "    x_dum_f = torch.ones((batch_size,1)).float().to(device)\n",
        "    # 予測時のダミー変数\n",
        "    x_dum_p = torch.ones((len(x_test),1)).float().to(device)\n",
        "\n",
        "    # 評価結果記録用 (損失関数値と精度)\n",
        "    history = np.zeros((0, 3))\n",
        "\n",
        "    # データローダー初期化(ミニバッチ処理用)\n",
        "    dataset = TensorDataset(torch.arange(M))\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # 繰り返し回数カウンタ初期化\n",
        "    epoch = 0\n",
        "\n",
        "    # 繰り返し計算\n",
        "    while epoch < epochs:\n",
        "        # 学習対象の選択(ミニバッチ学習法)\n",
        "        for batch in loader:\n",
        "            index = batch[0]\n",
        "            x = x_train_gpu[index]\n",
        "            yt = y_train_ohe_gpu[index]\n",
        "\n",
        "            # 予測計算 (順伝播)\n",
        "            a = x @ V\n",
        "            b = sigmoid(a)\n",
        "            b1 = torch.cat((x_dum_f, b), dim=1)\n",
        "            u = b1 @ W\n",
        "            yp = softmax(u)\n",
        "\n",
        "            # 誤差計算 (逆伝播)\n",
        "            yd = yp - yt\n",
        "            bd = b * (1-b) * (yd @ W[1:].T)\n",
        "\n",
        "            # 勾配計算\n",
        "            grad_W = (b1.T @ yd) / batch_size\n",
        "            grad_V = (x.T  @ bd) / batch_size\n",
        "\n",
        "            # パラメータ更新\n",
        "            W -= alpha * grad_W\n",
        "            V -= alpha * grad_V\n",
        "\n",
        "        score, loss = evaluate(x_test_gpu, y_test_gpu, y_test_ohe_gpu, x_dum_p, V, W)\n",
        "        history = np.vstack((history, np.array([epoch, loss, score])))\n",
        "        epoch = epoch + 1\n",
        "        if (epoch-1) % his_unit == 0:\n",
        "            print(f'epoch = {epoch-1} loss = {loss:.04f} score = {score:.04f}')\n",
        "\n",
        "    return W, V, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLSsbkU723M6"
      },
      "source": [
        "#### 学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YLs7D0L2xp1"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# 学習\n",
        "\n",
        "# 学習パラメータ\n",
        "hidden_units = 100  # 隠れ層サイズ\n",
        "alpha_np = 0.01     # 学習率\n",
        "batch_size = 500    # バッチサイズ\n",
        "epochs = 500        # 繰り返し数\n",
        "his_unit = 10       # 画面表示頻度\n",
        "\n",
        "# 繰り返し処理\n",
        "W, V, history1 = train_mlp(\n",
        "    hidden_units=hidden_units,\n",
        "    alpha_np=alpha_np, batch_size=batch_size,\n",
        "    epochs=epochs, his_unit=his_unit)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a89w54wuln6S"
      },
      "source": [
        "### 結果分析"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p3Q72Yklrgw"
      },
      "source": [
        "#### 損失と精度確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd_8u5NcY2XF"
      },
      "outputs": [],
      "source": [
        "# 損失と精度の確認\n",
        "# 損失と精度の初期値と最終値を確認\n",
        "print(f'初期状態: 関数:{history1[0,1]:.04f} \\\n",
        "精度:{history1[0,2]:.04f}')\n",
        "print(f'最終状態: 関数:{history1[-1,1]:.04f} \\\n",
        "精度:{history1[-1,2]:.04f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMNy8_2amlv_"
      },
      "source": [
        "#### 学習曲線(損失)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIn8wSAyly9z"
      },
      "outputs": [],
      "source": [
        "# 学習曲線(損失)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(history1[:,0], history1[:,1], 'b')\n",
        "plt.ylim(0,2.5)\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAVYQ-f8mr_K"
      },
      "source": [
        "#### 学習曲線(精度)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbfDBBzFmvaa"
      },
      "outputs": [],
      "source": [
        "# 学習曲線(精度)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(history1[:,0], history1[:,2], 'b')\n",
        "plt.ylim(0,1)\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10-11 プログラム実装(学習その2)"
      ],
      "metadata": {
        "id": "HN3W0nhd_Kog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習( パラメータ初期値変更)"
      ],
      "metadata": {
        "id": "TCNmcpCd_l9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 重み行列初期化改訂版"
      ],
      "metadata": {
        "id": "qVMkj3_cTae5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 重み行列初期化改訂版\n",
        "hidden_units = 100  # 隠れ層サイズ\n",
        "M, D  = x_train.shape\n",
        "N = y_train_ohe.shape[1]\n",
        "H = hidden_units\n",
        "H1 = H + 1\n",
        "np.random.seed(123)\n",
        "V_np = np.random.randn(D, H) / np.sqrt(D / 2)\n",
        "W_np = np.random.randn(H1, N) / np.sqrt(H1 / 2)\n",
        "\n",
        "# 内容の一部確認\n",
        "print(V_np[:2,:5])\n",
        "print(W_np[:2,:5])"
      ],
      "metadata": {
        "id": "IPk3UwjgTkXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 学習関数2"
      ],
      "metadata": {
        "id": "96L7Rs5z_21F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習関数2\n",
        "\n",
        "def train_mlp2(\n",
        "    hidden_units=100, epochs=500, batch_size=500, alpha_np=0.01,\n",
        "    his_unit=10):\n",
        "    \"\"\"\n",
        "    2層（入力→Sigmoid→出力Softmax）の単純なMLPを、\n",
        "    勾配降下法で学習する関数。\n",
        "    返り値: (V, W, history[epoch, loss, acc])\n",
        "    \"\"\"\n",
        "    # M: 訓練用系列データ総数\n",
        "    # D: 入力データ次元数\n",
        "    M, D  = x_train.shape\n",
        "    # N: 分類クラス数\n",
        "    N = y_train_ohe.shape[1]\n",
        "    # 隠れ層のノード数\n",
        "    H = hidden_units\n",
        "    H1 = H + 1\n",
        "    # 重み行列初期化改訂版\n",
        "    np.random.seed(123)\n",
        "    V_np = np.random.randn(D, H) / np.sqrt(D / 2)\n",
        "    W_np = np.random.randn(H1, N) / np.sqrt(H1 / 2)\n",
        "    # GPU転送\n",
        "    alpha = torch.tensor(alpha_np).float().to(device)\n",
        "    V = torch.tensor(V_np).float().to(device)\n",
        "    W = torch.tensor(W_np).float().to(device)\n",
        "\n",
        "    # 学習時のダミー変数\n",
        "    x_dum_f = torch.ones((batch_size,1)).float().to(device)\n",
        "    # 予測時のダミー変数\n",
        "    x_dum_p = torch.ones((len(x_test),1)).float().to(device)\n",
        "\n",
        "    # 評価結果記録用 (損失関数値と精度)\n",
        "    history = np.zeros((0, 3))\n",
        "\n",
        "    # データローダー初期化(ミニバッチ処理用)\n",
        "    dataset = TensorDataset(torch.arange(M))\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    # 繰り返し回数カウンタ初期化\n",
        "    epoch = 0\n",
        "\n",
        "    # 繰り返し計算\n",
        "    while epoch < epochs:\n",
        "        # 学習対象の選択(ミニバッチ学習法)\n",
        "        for batch in loader:\n",
        "            index = batch[0]\n",
        "            x = x_train_gpu[index]\n",
        "            yt = y_train_ohe_gpu[index]\n",
        "\n",
        "            # 予測計算 (順伝播)\n",
        "            a = x @ V\n",
        "            b = sigmoid(a)\n",
        "            b1 = torch.cat((x_dum_f, b), dim=1)\n",
        "            u = b1 @ W\n",
        "            yp = softmax(u)\n",
        "\n",
        "            # 誤差計算 (逆伝播)\n",
        "            yd = yp - yt\n",
        "            bd = b * (1-b) * (yd @ W[1:].T)\n",
        "\n",
        "            # 勾配計算\n",
        "            grad_W = (b1.T @ yd) / batch_size\n",
        "            grad_V = (x.T  @ bd) / batch_size\n",
        "\n",
        "            # パラメータ更新\n",
        "            W -= alpha * grad_W\n",
        "            V -= alpha * grad_V\n",
        "\n",
        "        score, loss = evaluate(x_test_gpu, y_test_gpu, y_test_ohe_gpu, x_dum_p, V, W)\n",
        "        history = np.vstack((history, np.array([epoch, loss, score])))\n",
        "        epoch = epoch + 1\n",
        "        if (epoch-1) % his_unit == 0:\n",
        "            print(f'epoch = {epoch-1} loss = {loss:.04f} score = {score:.04f}')\n",
        "\n",
        "    return W, V, history"
      ],
      "metadata": {
        "id": "zeonwriG_7Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 学習"
      ],
      "metadata": {
        "id": "qDS--jhmADoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# 学習\n",
        "\n",
        "# 学習パラメータ\n",
        "hidden_units = 100  # 隠れ層サイズ\n",
        "alpha_np = 0.01     # 学習率\n",
        "batch_size = 500    # バッチサイズ\n",
        "epochs = 500        # 繰り返し数\n",
        "his_unit = 10       # 画面表示頻度\n",
        "\n",
        "# 繰り返し処理\n",
        "W, V, history2 = train_mlp2(\n",
        "    hidden_units=hidden_units,\n",
        "    alpha_np=alpha_np, batch_size=batch_size,\n",
        "    epochs=epochs, his_unit=his_unit)"
      ],
      "metadata": {
        "id": "3pR6c7ZqGSif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 結果分析"
      ],
      "metadata": {
        "id": "S09UjwwlA-ZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 損失と精度の確認"
      ],
      "metadata": {
        "id": "Xw4cjkf9BDhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失と精度の確認\n",
        "# 損失と精度の初期値と最終値を確認\n",
        "print(f'初期状態: 損失:{history2[0,1]:.04f} \\\n",
        "精度:{history2[0,2]:.04f}')\n",
        "print(f'最終状態: 損失:{history2[-1,1]:.04f} \\\n",
        "精度:{history2[-1,2]:.04f}')"
      ],
      "metadata": {
        "id": "wWAVifhnBH0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 学習曲線(損失)"
      ],
      "metadata": {
        "id": "GXAcgsMoBNY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線(損失)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(history2[:,0], history2[:,1], 'b')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5dqBc4rrBR5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 学習曲線(精度)"
      ],
      "metadata": {
        "id": "cpdNX3ipBY4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線(精度)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(history2[:,0], history2[:,2], 'b')\n",
        "plt.ylim(0.4,1)\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3LJZHMMtBc2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJVmLZGHyRmf"
      },
      "source": [
        "#### イメージで確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-GujHJsyXtJ"
      },
      "outputs": [],
      "source": [
        "# イメージで確認\n",
        "\n",
        "N1 = 10 # 横個数\n",
        "N2 = 5  # 縦個数\n",
        "N = N1 * N2 # 10*5 = 50個\n",
        "\n",
        "# テストデータからランダムに50個のイメージを抽出\n",
        "# 再現性があるようにseed値をセットしておく\n",
        "np.random.seed(12)\n",
        "indexes = np.random.choice(y_test.shape[0], N, replace=False)\n",
        "x_selected = x_test_gpu[indexes]\n",
        "x_selected_show = x_test_np[indexes]\n",
        "y_selected = y_test_gpu[indexes]\n",
        "\n",
        "# ダミー変数の準備\n",
        "x_dum3 = torch.ones((N,1)).float().to(device)\n",
        "\n",
        "# 予測値の計算\n",
        "# テストデータに対して隠れ層の値を計算\n",
        "b_test = sigmoid(x_selected @ V)\n",
        "\n",
        "# ダミー変数追加\n",
        "b1_test = torch.cat((x_dum3, b_test), dim=1)\n",
        "\n",
        "# 予測値の計算(確率値)\n",
        "yp_test_ohe = softmax(b1_test @ W)\n",
        "\n",
        "# 予測クラス計算(0から9の整数)\n",
        "yp_test = torch.argmax(yp_test_ohe, dim=1)\n",
        "\n",
        "# 50個の描画領域を設定\n",
        "plt.figure(figsize=(N1, N2), tight_layout=True)\n",
        "for i in range(N):\n",
        "\n",
        "    # 描画位置指定\n",
        "    ax = plt.subplot(N2, N1, i + 1)\n",
        "\n",
        "    # 画像イメージ表示\n",
        "    ax.imshow(x_selected_show[i].reshape(28, 28),cmap='gray_r')\n",
        "\n",
        "    # 正解ラベルと予測値\n",
        "    true_label = int(y_selected[i])\n",
        "    pred_label = int(yp_test[i])\n",
        "\n",
        "    # タイトル色を条件で変更\n",
        "    title_color = 'blue' if true_label != pred_label else 'black'\n",
        "\n",
        "    # タイトル表示\n",
        "    ax.set_title(f'{true_label}:{pred_label}', fontsize=14, color=title_color)\n",
        "\n",
        "    # 軸ラベル非表示\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10-12 プログラム実装(学習その3)"
      ],
      "metadata": {
        "id": "oG4Wy84uBxy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習"
      ],
      "metadata": {
        "id": "8mKK9yPo9Cfq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 学習"
      ],
      "metadata": {
        "id": "t-o1TvEkB6UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# 学習\n",
        "\n",
        "# 学習パラメータ\n",
        "hidden_units = 100  # 隠れ層サイズ\n",
        "alpha_np = 0.01     # 学習率\n",
        "#batch_size = 500   # バッチサイズ前回値\n",
        "batch_size = 100    # バッチサイズ今回値\n",
        "epochs = 500        # 繰り返し数\n",
        "his_unit = 10       # 画面表示頻度\n",
        "\n",
        "# 繰り返し処理\n",
        "W, V, history3 = train_mlp2(\n",
        "    hidden_units=hidden_units,\n",
        "    alpha_np=alpha_np, batch_size=batch_size,\n",
        "    epochs=epochs, his_unit=his_unit)\n"
      ],
      "metadata": {
        "id": "xMgUIkeS8dMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 結果分析"
      ],
      "metadata": {
        "id": "2tgV7P1DGCe1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 損失と精度の確認"
      ],
      "metadata": {
        "id": "W2wipoivGFv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失と精度の確認\n",
        "# 損失と精度の初期値と最終値を確認\n",
        "print(f'初期状態: 損失:{history3[0,1]:.04f} \\\n",
        "精度:{history3[0,2]:.04f}')\n",
        "print(f'最終状態: 損失:{history3[-1,1]:.04f} \\\n",
        "精度:{history3[-1,2]:.04f}')"
      ],
      "metadata": {
        "id": "tz0oK2opGBqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 学習曲線(損失)"
      ],
      "metadata": {
        "id": "8TsoEe-EGNzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線(損失)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(history3[:,0], history3[:,1], 'b')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1hs351TCGTbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 学習曲線(精度)"
      ],
      "metadata": {
        "id": "Ii-NiPIlGX91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線(精度)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(history3[:,0], history3[:,2], 'b')\n",
        "plt.ylim(0.4,1)\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vG4Zp3xbGewL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### イメージで確認"
      ],
      "metadata": {
        "id": "6WSCgEfrGiv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# イメージで確認\n",
        "\n",
        "N1 = 10 # 横個数\n",
        "N2 = 5  # 縦個数\n",
        "N = N1 * N2 # 10*5 = 50個\n",
        "\n",
        "# テストデータからランダムに50個のイメージを抽出\n",
        "# 再現性があるようにseed値をセットしておく\n",
        "np.random.seed(12)\n",
        "indexes = np.random.choice(y_test.shape[0], N, replace=False)\n",
        "x_selected = x_test_gpu[indexes]\n",
        "x_selected_show = x_test_np[indexes]\n",
        "y_selected = y_test_gpu[indexes]\n",
        "\n",
        "# ダミー変数の準備\n",
        "x_dum3 = torch.ones((N,1)).float().to(device)\n",
        "\n",
        "# 予測値の計算\n",
        "# テストデータに対して隠れ層の値を計算\n",
        "b_test = sigmoid(x_selected @ V)\n",
        "\n",
        "# ダミー変数追加\n",
        "b1_test = torch.cat((x_dum3, b_test), dim=1)\n",
        "\n",
        "# 予測値の計算(確率値)\n",
        "yp_test_ohe = softmax(b1_test @ W)\n",
        "\n",
        "# 予測クラス計算(0から9の整数)\n",
        "yp_test = torch.argmax(yp_test_ohe, dim=1)\n",
        "\n",
        "# 50個の描画領域を設定\n",
        "plt.figure(figsize=(N1, N2), tight_layout=True)\n",
        "for i in range(N):\n",
        "\n",
        "    # 描画位置指定\n",
        "    ax = plt.subplot(N2, N1, i + 1)\n",
        "\n",
        "    # 画像イメージ表示\n",
        "    ax.imshow(x_selected_show[i].reshape(28, 28),cmap='gray_r')\n",
        "\n",
        "    # 正解ラベルと予測値\n",
        "    true_label = int(y_selected[i])\n",
        "    pred_label = int(yp_test[i])\n",
        "\n",
        "    # タイトル色を条件で変更\n",
        "    title_color = 'blue' if true_label != pred_label else 'black'\n",
        "\n",
        "    # タイトル表示\n",
        "    ax.set_title(f'{true_label}:{pred_label}', fontsize=14, color=title_color)\n",
        "\n",
        "    # 軸ラベル非表示\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1-O76zqcGliA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10-13 プログラム実装(学習その4)"
      ],
      "metadata": {
        "id": "tAax3JFL0ve8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 関数定義"
      ],
      "metadata": {
        "id": "V7QD8qL0BLy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### evaluate2関数\n",
        "隠れ層2層向けの評価関数"
      ],
      "metadata": {
        "id": "OZBqRHfCBXUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate2関数\n",
        "def evaluate2(x_test, y_test, y_test_ohe, x_dum_p, U, V, W):\n",
        "\n",
        "    # テストデータに対して隠れ層の値を計算\n",
        "    b_test = sigmoid(x_test @ U)\n",
        "\n",
        "    # ダミー変数追加\n",
        "    b1_test = torch.cat((x_dum_p, b_test), dim=1)\n",
        "\n",
        "    d_test = sigmoid(b1_test @ V)\n",
        "\n",
        "    # ダミー変数追加\n",
        "    d1_test = torch.cat((x_dum_p, d_test), dim=1)\n",
        "\n",
        "    # 予測値算出\n",
        "    yp_test_ohe = softmax(d1_test @ W)\n",
        "\n",
        "    # ラベル値算出\n",
        "    yp_test = torch.argmax(yp_test_ohe, dim=1)\n",
        "\n",
        "    # 損失計算(item関数でスカラー化)\n",
        "    loss = cross_entropy(y_test_ohe, yp_test_ohe).item()\n",
        "\n",
        "    # 精度計算(item関数でスカラー化)\n",
        "    score = (y_test == yp_test).float().mean().item()\n",
        "\n",
        "    return score, loss"
      ],
      "metadata": {
        "id": "qlc1k5BEBaa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習(隠れ層2層化)"
      ],
      "metadata": {
        "id": "qkngNcpI04NR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 学習関数3"
      ],
      "metadata": {
        "id": "SshyNSPsdDlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mlp3(\n",
        "    hidden_units=100, epochs=500, batch_size=500, alpha_np=0.01,\n",
        "    his_unit=10):\n",
        "    \"\"\"\n",
        "    3層（入力→Sigmoid→出力Softmax）の単純なMLPを、\n",
        "    勾配降下法で学習する関数。\n",
        "    返り値: (U, V, W, history[epoch, loss, acc])\n",
        "    \"\"\"\n",
        "    # M: 訓練用系列データ総数\n",
        "    # D: 入力データ次元数\n",
        "    M, D  = x_train.shape\n",
        "    # N: 分類クラス数\n",
        "    N = y_train_ohe.shape[1]\n",
        "    # 隠れ層のノード数\n",
        "    H = hidden_units\n",
        "    H1 = H + 1\n",
        "    # 重み行列初期化改訂版\n",
        "    np.random.seed(123)\n",
        "    U_np = np.random.randn(D, H) / np.sqrt(D / 2)\n",
        "    V_np = np.random.randn(H1, H) / np.sqrt(H1 / 2)\n",
        "    W_np = np.random.randn(H1, N) / np.sqrt(H1 / 2)\n",
        "    # GPU転送\n",
        "    alpha = torch.tensor(alpha_np).float().to(device)\n",
        "    U = torch.tensor(U_np).float().to(device)\n",
        "    V = torch.tensor(V_np).float().to(device)\n",
        "    W = torch.tensor(W_np).float().to(device)\n",
        "\n",
        "    # 学習時のダミー変数\n",
        "    x_dum_f = torch.ones((batch_size,1)).float().to(device)\n",
        "    # 予測時のダミー変数\n",
        "    x_dum_p = torch.ones((len(x_test),1)).float().to(device)\n",
        "\n",
        "    # 評価結果記録用 (損失関数値と精度)\n",
        "    history = np.zeros((0, 3))\n",
        "\n",
        "    # データローダー初期化(ミニバッチ処理用)\n",
        "    dataset = TensorDataset(torch.arange(M))\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    # 繰り返し回数カウンタ初期化\n",
        "    epoch = 0\n",
        "\n",
        "    # 繰り返し計算\n",
        "    while epoch < epochs:\n",
        "        # 学習対象の選択(ミニバッチ学習法)\n",
        "        for batch in loader:\n",
        "            index = batch[0]\n",
        "            x = x_train_gpu[index]\n",
        "            yt = y_train_ohe_gpu[index]\n",
        "\n",
        "            # 予測計算 (順伝播)\n",
        "            a = x @ U\n",
        "            b = sigmoid(a)\n",
        "            b1 = torch.cat((x_dum_f, b), dim=1)\n",
        "            c = b1 @ V\n",
        "            d = sigmoid(c)\n",
        "            d1 = torch.cat((x_dum_f, d), dim=1)\n",
        "            u = d1 @ W\n",
        "            yp = softmax(u)\n",
        "\n",
        "            # 誤差計算 (逆伝播)\n",
        "            yd = yp - yt\n",
        "            dd = d * (1-d) * torch.tensor(yd @ W[1:].T)\n",
        "            bd = b * (1-b) * torch.tensor(dd @ V[1:].T)\n",
        "\n",
        "            # 勾配計算\n",
        "            grad_W = (d1.T @ yd) / batch_size\n",
        "            grad_V = (b1.T  @ dd) / batch_size\n",
        "            grad_U = (x.T @ bd) / batch_size\n",
        "\n",
        "            # パラメータ更新\n",
        "            W -= alpha * grad_W\n",
        "            V -= alpha * grad_V\n",
        "            U -= alpha * grad_U\n",
        "\n",
        "        score, loss = evaluate2(x_test_gpu, y_test_gpu, y_test_ohe_gpu,\n",
        "                                x_dum_p, U, V, W)\n",
        "        history = np.vstack((history, np.array([epoch, loss, score])))\n",
        "        epoch = epoch + 1\n",
        "        if (epoch-1) % his_unit == 0:\n",
        "            print(f'epoch = {epoch-1} loss = {loss:.04f} score = {score:.04f}')\n",
        "    return U, W, V, history"
      ],
      "metadata": {
        "id": "fBXi9akrdHj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 学習"
      ],
      "metadata": {
        "id": "WfYRFzurjDYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# 学習\n",
        "\n",
        "# 学習パラメータ\n",
        "hidden_units = 100  # 隠れ層サイズ\n",
        "alpha_np = 0.01     # 学習率\n",
        "#batch_size = 500   # バッチサイズ前回値\n",
        "batch_size = 100    # バッチサイズ今回値\n",
        "epochs = 1000        # 繰り返し数\n",
        "his_unit = 10       # 画面表示頻度\n",
        "\n",
        "# 繰り返し処理\n",
        "U, W, V, history4 = train_mlp3(\n",
        "    hidden_units=hidden_units,\n",
        "    alpha_np=alpha_np, batch_size=batch_size,\n",
        "    epochs=epochs, his_unit=his_unit)\n"
      ],
      "metadata": {
        "id": "Fn8mvDfbjGM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 結果分析その4"
      ],
      "metadata": {
        "id": "KrsdSZn9Drza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 損失と精度の確認"
      ],
      "metadata": {
        "id": "J8RBfnVkDxhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失と精度の確認\n",
        "# 損失と精度の初期値と最終値を確認\n",
        "print(f'初期状態: 損失:{history4[0,1]:.04f} \\\n",
        "精度:{history4[0,2]:.04f}')\n",
        "print(f'最終状態: 損失:{history4[-1,1]:.04f} \\\n",
        "精度:{history4[-1,2]:.04f}')"
      ],
      "metadata": {
        "id": "gkPGNZBoD3YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 学習曲線(損失)"
      ],
      "metadata": {
        "id": "xTkfQ0kMFRpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線(損失)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(history4[:,0], history4[:,1], 'b')\n",
        "plt.ylim(0,0.5)\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jySIXlUBFYDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 学習曲線(精度)"
      ],
      "metadata": {
        "id": "mNTUawXSFgk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線(精度)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(history4[:,0], history4[:,2], 'b')\n",
        "plt.ylim(0.4,1)\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OZNT1YqRFm0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### イメージで確認"
      ],
      "metadata": {
        "id": "cgWZpgoOFuoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# イメージで確認\n",
        "\n",
        "N1 = 10 # 横個数\n",
        "N2 = 5  # 縦個数\n",
        "N = N1 * N2 # 10*5 = 50個\n",
        "\n",
        "# テストデータからランダムに50個のイメージを抽出\n",
        "# 再現性があるようにseed値をセットしておく\n",
        "np.random.seed(12)\n",
        "indexes = np.random.choice(y_test.shape[0], N, replace=False)\n",
        "x_selected = x_test_gpu[indexes]\n",
        "x_selected_show = x_test_np[indexes]\n",
        "y_selected = y_test_gpu[indexes]\n",
        "\n",
        "# ダミー変数の準備\n",
        "x_dum_i = torch.ones((N,1)).float().to(device)\n",
        "\n",
        "# 予測値の計算(隠れ層1層目)\n",
        "b_test = sigmoid(x_selected @ U)\n",
        "\n",
        "# ダミー変数追加\n",
        "b1_test = torch.cat((x_dum_i, b_test), dim=1)\n",
        "\n",
        "# 予測値の計算(隠れ層2層目)\n",
        "d_test = sigmoid(b1_test @ V)\n",
        "\n",
        "# ダミー変数追加\n",
        "d1_test = torch.cat((x_dum_i, d_test), dim=1)\n",
        "\n",
        "# 予測値の計算(確率値)\n",
        "yp_test_ohe = softmax(d1_test @ W)\n",
        "\n",
        "# 予測クラス計算(0から9の整数)\n",
        "yp_test = torch.argmax(yp_test_ohe, dim=1)\n",
        "\n",
        "# 50個の描画領域を設定\n",
        "plt.figure(figsize=(N1, N2), tight_layout=True)\n",
        "for i in range(N):\n",
        "\n",
        "    # 描画位置指定\n",
        "    ax = plt.subplot(N2, N1, i + 1)\n",
        "\n",
        "    # 画像イメージ表示\n",
        "    ax.imshow(x_selected_show[i].reshape(28, 28),cmap='gray_r')\n",
        "\n",
        "    # 正解ラベルと予測値\n",
        "    true_label = int(y_selected[i])\n",
        "    pred_label = int(yp_test[i])\n",
        "\n",
        "    # タイトル色を条件で変更\n",
        "    title_color = 'blue' if true_label != pred_label else 'black'\n",
        "\n",
        "    # タイトル表示\n",
        "    ax.set_title(f'{true_label}:{pred_label}', fontsize=14, color=title_color)\n",
        "\n",
        "    # 軸ラベル非表示\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yxnVUi1vFy6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O2PLFyUxel2"
      },
      "source": [
        "### バージョン確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvspbaTyzV2O"
      },
      "outputs": [],
      "source": [
        "!pip install watermark -qq\n",
        "%load_ext watermark\n",
        "%watermark --iversions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUoEkx4_1phL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}